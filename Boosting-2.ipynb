{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d664b1c-30a1-4f44-a28e-566d985cd530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1\n",
    "\n",
    "Gradient boosting regression trees are based on the idea of an ensemble method derived from a decision tree. The decision tree uses a tree structure. Starting from tree root, branching according to the conditions and heading toward the leaves, the goal leaf is the prediction result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56a7740-7a0f-4225-9e1f-23cfa7dee8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "class GradientBoostingRegressor:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.models = []\n",
    "        self.residuals = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Initialize with the mean of y\n",
    "        mean_y = np.mean(y)\n",
    "        self.models.append(mean_y)\n",
    "        self.residuals.append(y - mean_y)\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            # Fit a decision tree to the residuals\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, self.residuals[i])\n",
    "            self.models.append(tree)\n",
    "            \n",
    "            # Predict the residuals and update them\n",
    "            y_pred = tree.predict(X)\n",
    "            self.residuals.append(self.residuals[i] - self.learning_rate * y_pred)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(len(X))\n",
    "        for tree in self.models[1:]:\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "        return y_pred + self.models[0]\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        mse = mean_squared_error(y, y_pred)\n",
    "        r2 = r2_score(y, y_pred)\n",
    "        return mse, r2\n",
    "# Generate synthetic data\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(100, 1) * 10\n",
    "y = 2 * (X[:, 0] ** 2) + 1 + np.random.randn(100) * 2\n",
    "\n",
    "# Instantiate and train the gradient boosting regressor\n",
    "gb_regressor = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "gb_regressor.fit(X, y)\n",
    "\n",
    "# Evaluate the model\n",
    "mse, r2 = gb_regressor.evaluate(X, y)\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1692d29-0910-4a77-8d37-d3b2eb8d999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
    "class GradientBoostingRegressor:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.models = []\n",
    "        self.residuals = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Initialize with the mean of y\n",
    "        mean_y = np.mean(y)\n",
    "        self.models.append(mean_y)\n",
    "        self.residuals.append(y - mean_y)\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            # Fit a decision tree to the residuals\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, self.residuals[i])\n",
    "            self.models.append(tree)\n",
    "            \n",
    "            # Predict the residuals and update them\n",
    "            y_pred = tree.predict(X)\n",
    "            self.residuals.append(self.residuals[i] - self.learning_rate * y_pred)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(len(X))\n",
    "        for tree in self.models[1:]:\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "        return y_pred + self.models[0]\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return r2_score(y, y_pred)\n",
    "\n",
    "# Define scorer for GridSearchCV\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "# Parameter grid for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'max_depth': [2, 3, 4]\n",
    "}\n",
    "\n",
    "# Create GradientBoostingRegressor object\n",
    "gb_regressor = GradientBoostingRegressor()\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=gb_regressor, param_grid=param_grid, cv=5, scoring=mse_scorer)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print best parameters and best score\n",
    "print(\"Best Parameters found by Grid Search:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"Best Mean Squared Error:\", -grid_search.best_score_)  # Convert back to positive since scorer is negative MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f94a36-621e-4947-9525-66b9c3071761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 4\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
